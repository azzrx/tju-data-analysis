# RAG æ¶æ„å®ç°è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

æœ¬ç³»ç»Ÿå®ç°äº†**å…ˆè¿›çš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰æ¶æ„**ï¼Œé€šè¿‡æ··åˆæ£€ç´¢ã€æŸ¥è¯¢ä¼˜åŒ–ã€é‡æ’åºç­‰æŠ€æœ¯ï¼Œå®ç°ç²¾å‡†çš„æ•°æ®åˆ†æã€‚ç³»ç»Ÿé‡‡ç”¨**BM25 + å‘é‡æ£€ç´¢**çš„æ··åˆç­–ç•¥ï¼Œç»“åˆ**æŸ¥è¯¢ä¼˜åŒ–**å’Œ**æ™ºèƒ½é‡æ’åº**ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢å‡†ç¡®ç‡å’Œå¬å›ç‡ã€‚

---

## ğŸ—ï¸ RAG æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å‰ç«¯å±‚ (Frontend)                   â”‚
â”‚  - ç”¨æˆ·è¾“å…¥æŸ¥è¯¢                      â”‚
â”‚  - é€‰æ‹©æŸ¥è¯¢ç±»å‹ (analysis)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“ HTTP API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API è·¯ç”±å±‚ (api.py)                 â”‚
â”‚  - æ¥æ”¶ query_type="analysis"        â”‚
â”‚  - è°ƒç”¨ RAG ç³»ç»Ÿ                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG ç³»ç»Ÿå±‚ (topklogsystem.py)       â”‚
â”‚  - æŸ¥è¯¢ä¼˜åŒ–å™¨                        â”‚
â”‚  - æ··åˆæ£€ç´¢å™¨                        â”‚
â”‚  - é‡æ’åºå™¨                          â”‚
â”‚  - LLM ç”Ÿæˆ                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å‘é‡å­˜å‚¨å±‚ (ChromaDB)               â”‚
â”‚  - å‘é‡ç´¢å¼•                         â”‚
â”‚  - æ–‡æ¡£å­˜å‚¨                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å®Œæ•´ RAG æµç¨‹

```
ç”¨æˆ·æŸ¥è¯¢
    â†“
æŸ¥è¯¢ä¼˜åŒ–ï¼ˆé‡å†™ã€æ‰©å±•ã€æ„å›¾è¯†åˆ«ï¼‰
    â†“
æ··åˆæ£€ç´¢ï¼ˆBM25 + å‘é‡æ£€ç´¢ï¼‰
    â†“
ç»“æœåˆå¹¶ï¼ˆåŠ æƒå¹³å‡ï¼‰
    â†“
å…ƒæ•°æ®è¿‡æ»¤ï¼ˆçº§åˆ«ã€æœåŠ¡ã€ç»„ä»¶ï¼‰
    â†“
é‡æ’åºï¼ˆè§„åˆ™ + å¤šæ ·æ€§ï¼‰
    â†“
æ„å»º Promptï¼ˆæ£€ç´¢ç»“æœ + ç”¨æˆ·æŸ¥è¯¢ï¼‰
    â†“
LLM ç”Ÿæˆå›å¤
    â†“
è¿”å›åˆ†æç»“æœ
```

---

## ğŸ“ æ ¸å¿ƒå®ç°æ–‡ä»¶

### åç«¯æ–‡ä»¶

1. **æ··åˆæ£€ç´¢å™¨**: `django_backend/hybrid_retriever.py`
2. **æŸ¥è¯¢ä¼˜åŒ–å™¨**: `django_backend/query_optimizer.py`
3. **é‡æ’åºå™¨**: `django_backend/reranker.py`
4. **RAG ç³»ç»Ÿ**: `django_backend/topklogsystem.py`
5. **æœåŠ¡è°ƒç”¨**: `django_backend/deepseek_api/services.py` (ç¬¬ 140-183 è¡Œ)

### å‰ç«¯æ–‡ä»¶

1. **API æ¥å£**: `vue_frontend/src/api.js` (ç¬¬ 42-44 è¡Œ)
2. **æŸ¥è¯¢ç±»å‹é€‰æ‹©**: `vue_frontend/src/components/ChatInput.vue` (ç¬¬ 10-11 è¡Œ)

---

## ğŸ” è¯¦ç»†å®ç°è§£æ

## ä¸€ã€æ··åˆæ£€ç´¢å™¨ (`hybrid_retriever.py`)

### 1.1 æ ¸å¿ƒè®¾è®¡

æ··åˆæ£€ç´¢å™¨ç»“åˆäº†ä¸¤ç§æ£€ç´¢æ–¹æ³•ï¼š
- **å‘é‡æ£€ç´¢**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œç†è§£æŸ¥è¯¢æ„å›¾
- **BM25 æ£€ç´¢**ï¼šåŸºäºå…³é”®è¯åŒ¹é…ï¼Œç²¾ç¡®åŒ¹é…æœ¯è¯­

#### 1.1.1 åˆå§‹åŒ–

```python
class HybridRetriever:
    """
    æ··åˆæ£€ç´¢å™¨
    ç»“åˆ BM25 å…³é”®è¯æ£€ç´¢å’Œå‘é‡è¯­ä¹‰æ£€ç´¢
    """
    
    def __init__(
        self,
        vector_index: VectorStoreIndex,
        documents: List[Dict[str, str]],
        alpha: float = 0.5
    ):
        """
        Args:
            vector_index: llama-index çš„å‘é‡ç´¢å¼•
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£æ˜¯ {"text": "...", "metadata": {...}}
            alpha: å‘é‡æ£€ç´¢æƒé‡ï¼ˆ0-1ï¼‰ï¼Œbeta = 1 - alpha ä¸º BM25 æƒé‡
        """
        self.vector_index = vector_index
        self.documents = documents
        self.alpha = float(alpha)  # å‘é‡æ£€ç´¢æƒé‡
        self.beta = 1.0 - self.alpha  # BM25 æƒé‡
        
        # æ„å»º BM25 ç´¢å¼•
        if self.bm25_enabled:
            self._build_bm25_index()
        
        # æå–å…ƒæ•°æ®
        self._extract_metadata()
```

**è®¾è®¡è¦ç‚¹**ï¼š
- âœ… **æƒé‡å¯è°ƒ**ï¼š`alpha` æ§åˆ¶å‘é‡æ£€ç´¢å’Œ BM25 çš„æƒé‡æ¯”ä¾‹
- âœ… **å®¹é”™æœºåˆ¶**ï¼šBM25 ä¸å¯ç”¨æ—¶è‡ªåŠ¨å›é€€åˆ°çº¯å‘é‡æ£€ç´¢
- âœ… **å…ƒæ•°æ®æå–**ï¼šè‡ªåŠ¨è§£ææ—¥å¿—å…ƒæ•°æ®ï¼ˆæœåŠ¡ã€çº§åˆ«ã€é”™è¯¯ç±»å‹ç­‰ï¼‰

#### 1.1.2 BM25 ç´¢å¼•æ„å»º

```python
def _build_bm25_index(self):
    """æ„å»º BM25 ç´¢å¼•"""
    # åˆ†è¯ï¼ˆä¸­æ–‡æŒ‰å­—ç¬¦åˆ†ï¼Œè‹±æ–‡æŒ‰å•è¯åˆ†ï¼‰
    tokenized_docs = []
    for doc in self.documents:
        text = doc.get("text", "")
        tokens = self._tokenize(text)
        tokenized_docs.append(tokens)
    
    # æ„å»º BM25 ç´¢å¼•
    self.bm25 = BM25Okapi(tokenized_docs)
    self.tokenized_docs = tokenized_docs

def _tokenize(self, text: str) -> List[str]:
    """åˆ†è¯å‡½æ•°ï¼šä¸­æ–‡æŒ‰å­—ç¬¦åˆ†ï¼Œè‹±æ–‡æŒ‰å•è¯åˆ†"""
    pattern = r'[a-zA-Z0-9_]+|[\u4e00-\u9fff]'
    matches = re.findall(pattern, text.lower())
    return matches
```

**åˆ†è¯ç­–ç•¥**ï¼š
- ä¸­æ–‡ï¼šæŒ‰å­—ç¬¦åˆ†å‰²ï¼ˆæ”¯æŒå•å­—åŒ¹é…ï¼‰
- è‹±æ–‡ï¼šæŒ‰å•è¯åˆ†å‰²ï¼ˆæ”¯æŒå®Œæ•´å•è¯åŒ¹é…ï¼‰
- æ•°å­—ï¼šä¿ç•™æ•°å­—åºåˆ—

#### 1.1.3 å…ƒæ•°æ®æå–

```python
def _parse_log_metadata(self, text: str) -> LogMetadata:
    """è§£ææ—¥å¿—å…ƒæ•°æ®"""
    metadata = LogMetadata()
    
    # è§£æ CSV æ ¼å¼ï¼šæœåŠ¡,çº§åˆ«,é”™è¯¯,æ¶ˆæ¯,ç»„ä»¶,åŸå› 
    if ',' in text:
        parts = [p.strip() for p in text.split(',')]
        if len(parts) >= 6:
            metadata.service = parts[0].strip("'\" ")
            metadata.level = parts[1].strip("'\" ")
            metadata.error_type = parts[2].strip("'\" ")
            metadata.component = parts[4].strip("'\" ")
    
    # è®¡ç®—ä¸¥é‡ç¨‹åº¦è¯„åˆ†
    metadata.severity_score = self._calculate_severity(metadata.level)
    
    return metadata

def _calculate_severity(self, level: Optional[str]) -> float:
    """è®¡ç®—æ—¥å¿—ä¸¥é‡ç¨‹åº¦è¯„åˆ†"""
    severity_map = {
        'FATAL': 1.0,
        'ERROR': 0.8,
        'WARN': 0.5,
        'WARNING': 0.5,
        'INFO': 0.2,
        'DEBUG': 0.1
    }
    return severity_map.get(level.upper() if level else None, 0.3)
```

**å…ƒæ•°æ®å­—æ®µ**ï¼š
- `service`: æœåŠ¡åç§°
- `level`: æ—¥å¿—çº§åˆ«ï¼ˆERRORã€WARNã€INFO ç­‰ï¼‰
- `error_type`: é”™è¯¯ç±»å‹
- `component`: ç»„ä»¶åç§°
- `severity_score`: ä¸¥é‡ç¨‹åº¦è¯„åˆ†ï¼ˆ0-1ï¼‰

### 1.2 æ··åˆæ£€ç´¢æµç¨‹

```python
def retrieve(
    self,
    query: str,
    top_k: int = 10,
    filters: Optional[Dict[str, Any]] = None,
    boost_recent: bool = False,
    boost_severity: bool = True
) -> List[RetrievalResult]:
    """
    æ··åˆæ£€ç´¢ä¸»æµç¨‹
    
    æ­¥éª¤ï¼š
    1. å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
    2. BM25 æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
    3. åˆå¹¶ç»“æœï¼ˆåŠ æƒå¹³å‡ï¼‰
    4. å…ƒæ•°æ®è¿‡æ»¤
    5. ä¸¥é‡æ€§æƒé‡æå‡
    6. æ’åºå¹¶è¿”å› top_k
    """
    # 1. å‘é‡æ£€ç´¢
    candidate_count = min(top_k * 2, 100)
    vector_results = self._vector_retrieve(query, candidate_count)
    
    # 2. BM25 æ£€ç´¢
    bm25_results = []
    if self.bm25_enabled:
        bm25_results = self._bm25_retrieve(query, candidate_count)
    
    # 3. åˆå¹¶ç»“æœ
    merged_results = self._merge_results(vector_results, bm25_results)
    
    # 4. åº”ç”¨å…ƒæ•°æ®è¿‡æ»¤
    if filters:
        merged_results = self._apply_filters(merged_results, filters)
    
    # 5. åº”ç”¨æƒé‡æå‡
    if boost_severity:
        merged_results = self._boost_by_severity(merged_results)
    
    # 6. æ’åºå¹¶è¿”å› top_k
    merged_results.sort(key=lambda x: x.score, reverse=True)
    return merged_results[:top_k]
```

#### 1.2.1 å‘é‡æ£€ç´¢

```python
def _vector_retrieve(self, query: str, top_k: int) -> List[RetrievalResult]:
    """å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰"""
    retriever = self.vector_index.as_retriever(similarity_top_k=top_k)
    nodes = retriever.retrieve(query)
    
    results = []
    for node in nodes:
        result = RetrievalResult(
            content=node.text,
            score=node.score if node.score else 0.5,
            metadata=self.doc_metadata[i] if i < len(self.doc_metadata) else LogMetadata(),
            source='vector',
            node_id=node.node_id
        )
        results.append(result)
    
    return results
```

**ç‰¹ç‚¹**ï¼š
- âœ… **è¯­ä¹‰ç†è§£**ï¼šåŸºäº embedding æ¨¡å‹ï¼Œç†è§£æŸ¥è¯¢æ„å›¾
- âœ… **ç›¸ä¼¼åº¦è¯„åˆ†**ï¼šè¿”å› 0-1 çš„ç›¸ä¼¼åº¦åˆ†æ•°

#### 1.2.2 BM25 æ£€ç´¢

```python
def _bm25_retrieve(self, query: str, top_k: int) -> List[RetrievalResult]:
    """BM25 æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰"""
    # åˆ†è¯
    query_tokens = self._tokenize(query)
    
    # BM25 è¯„åˆ†
    scores = self.bm25.get_scores(query_tokens)
    
    # è·å– top_kï¼ˆè¿‡æ»¤æ‰åˆ†æ•°ä¸º 0 çš„ç»“æœï¼‰
    valid_indices = [(i, float(scores[i])) for i in range(len(scores)) if float(scores[i]) > 0]
    valid_indices.sort(key=lambda x: x[1], reverse=True)
    top_indices = [idx for idx, _ in valid_indices[:top_k]]
    
    results = []
    for idx in top_indices:
        doc = self.documents[idx]
        result = RetrievalResult(
            content=doc.get("text", ""),
            score=float(scores[idx]),
            metadata=self.doc_metadata[idx],
            source='bm25'
        )
        results.append(result)
    
    return results
```

**ç‰¹ç‚¹**ï¼š
- âœ… **ç²¾ç¡®åŒ¹é…**ï¼šåŸºäºå…³é”®è¯åŒ¹é…ï¼Œé€‚åˆæœ¯è¯­æŸ¥è¯¢
- âœ… **TF-IDF å˜ä½“**ï¼šè€ƒè™‘è¯é¢‘å’Œé€†æ–‡æ¡£é¢‘ç‡

#### 1.2.3 ç»“æœåˆå¹¶

```python
def _merge_results(
    self,
    vector_results: List[RetrievalResult],
    bm25_results: List[RetrievalResult]
) -> List[RetrievalResult]:
    """åˆå¹¶å‘é‡æ£€ç´¢å’Œ BM25 æ£€ç´¢ç»“æœ"""
    # å½’ä¸€åŒ–åˆ†æ•°
    vector_results = self._normalize_scores(vector_results)
    bm25_results = self._normalize_scores(bm25_results)
    
    # ä½¿ç”¨å†…å®¹ä½œä¸ºå»é‡é”®
    result_map = {}
    
    # æ·»åŠ å‘é‡æ£€ç´¢ç»“æœ
    for result in vector_results:
        key = result.content[:100]  # ä½¿ç”¨å‰100ä¸ªå­—ç¬¦ä½œä¸ºé”®
        result.score = result.score * self.alpha  # å‘é‡æƒé‡
        result.source = 'hybrid'
        result_map[key] = result
    
    # åˆå¹¶ BM25 ç»“æœ
    for result in bm25_results:
        key = result.content[:100]
        if key in result_map:
            # å·²å­˜åœ¨ï¼Œåˆå¹¶åˆ†æ•°
            result_map[key].score += result.score * self.beta  # BM25 æƒé‡
        else:
            # æ–°ç»“æœ
            result.score = result.score * self.beta
            result.source = 'hybrid'
            result_map[key] = result
    
    return list(result_map.values())
```

**åˆå¹¶ç­–ç•¥**ï¼š
- âœ… **å½’ä¸€åŒ–**ï¼šå°†ä¸¤ç§æ£€ç´¢çš„åˆ†æ•°å½’ä¸€åŒ–åˆ° 0-1 èŒƒå›´
- âœ… **åŠ æƒå¹³å‡**ï¼š`final_score = alpha * vector_score + beta * bm25_score`
- âœ… **å»é‡**ï¼šç›¸åŒå†…å®¹çš„ç»“æœåˆå¹¶åˆ†æ•°

**æƒé‡é…ç½®**ï¼š
- é»˜è®¤ï¼š`alpha=0.6, beta=0.4`ï¼ˆå‘é‡ 60%ï¼ŒBM25 40%ï¼‰
- å¯æ ¹æ®åœºæ™¯è°ƒæ•´ï¼šè¯­ä¹‰æŸ¥è¯¢åå‘å‘é‡ï¼Œæœ¯è¯­æŸ¥è¯¢åå‘ BM25

#### 1.2.4 å…ƒæ•°æ®è¿‡æ»¤

```python
def _apply_filters(
    self,
    results: List[RetrievalResult],
    filters: Dict[str, Any]
) -> List[RetrievalResult]:
    """åº”ç”¨å…ƒæ•°æ®è¿‡æ»¤"""
    filtered = []
    
    for result in results:
        match = True
        
        # æ£€æŸ¥æ¯ä¸ªè¿‡æ»¤æ¡ä»¶
        if 'level' in filters:
            if result.metadata.level != filters['level']:
                match = False
        
        if 'service' in filters:
            if result.metadata.service != filters['service']:
                match = False
        
        if 'component' in filters:
            if result.metadata.component != filters['component']:
                match = False
        
        if 'min_severity' in filters:
            if result.metadata.severity_score < filters['min_severity']:
                match = False
        
        if match:
            filtered.append(result)
    
    return filtered
```

**æ”¯æŒçš„è¿‡æ»¤æ¡ä»¶**ï¼š
- `level`: æ—¥å¿—çº§åˆ«ï¼ˆERRORã€WARNã€INFO ç­‰ï¼‰
- `service`: æœåŠ¡åç§°
- `component`: ç»„ä»¶åç§°
- `min_severity`: æœ€å°ä¸¥é‡ç¨‹åº¦ï¼ˆ0-1ï¼‰

#### 1.2.5 ä¸¥é‡æ€§æƒé‡æå‡

```python
def _boost_by_severity(self, results: List[RetrievalResult]) -> List[RetrievalResult]:
    """æ ¹æ®ä¸¥é‡ç¨‹åº¦æå‡æƒé‡"""
    for result in results:
        # ä¸¥é‡æ€§è¶Šé«˜ï¼Œæƒé‡æå‡è¶Šå¤§
        severity_boost = 1.0 + result.metadata.severity_score * 0.5
        result.score *= severity_boost
    
    return results
```

**æå‡ç­–ç•¥**ï¼š
- FATAL (1.0): æå‡ 50%
- ERROR (0.8): æå‡ 40%
- WARN (0.5): æå‡ 25%
- INFO (0.2): æå‡ 10%

---

## äºŒã€æŸ¥è¯¢ä¼˜åŒ–å™¨ (`query_optimizer.py`)

### 2.1 æ ¸å¿ƒåŠŸèƒ½

æŸ¥è¯¢ä¼˜åŒ–å™¨è´Ÿè´£ï¼š
- **æŸ¥è¯¢é‡å†™**ï¼šç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“
- **æœ¯è¯­æ‰©å±•**ï¼šä½¿ç”¨åŒä¹‰è¯è¯å…¸æ‰©å±•æŸ¥è¯¢
- **æ„å›¾è¯†åˆ«**ï¼šè¯†åˆ«æŸ¥è¯¢æ„å›¾ï¼ˆé”™è¯¯è¯Šæ–­ã€è§£å†³æ–¹æ¡ˆã€æ—¥å¿—æœç´¢ï¼‰

#### 2.1.1 åŒä¹‰è¯è¯å…¸

```python
self.synonym_dict = {
    "é”™è¯¯": ["error", "å¼‚å¸¸", "exception", "å¤±è´¥", "failure", "bug", "é—®é¢˜"],
    "error": ["é”™è¯¯", "å¼‚å¸¸", "exception", "å¤±è´¥", "failure"],
    "è¿æ¥": ["connection", "é“¾æ¥", "connect"],
    "è¶…æ—¶": ["timeout", "time out", "è¶…è¿‡æ—¶é—´"],
    "æ•°æ®åº“": ["database", "db", "mysql", "postgresql", "mongo"],
    "æ€§èƒ½": ["performance", "é€Ÿåº¦", "æ…¢", "slow", "å»¶è¿Ÿ", "latency"],
    "å†…å­˜": ["memory", "mem", "ram", "oom"],
    # ... æ›´å¤šåŒä¹‰è¯
}
```

**è®¾è®¡è¦ç‚¹**ï¼š
- âœ… **ä¸­è‹±æ–‡æ”¯æŒ**ï¼šåŒæ—¶æ”¯æŒä¸­è‹±æ–‡åŒä¹‰è¯
- âœ… **é¢†åŸŸç‰¹å®š**ï¼šé’ˆå¯¹æ—¥å¿—åˆ†æé¢†åŸŸçš„ä¸“ä¸šæœ¯è¯­
- âœ… **å¯æ‰©å±•**ï¼šæ˜“äºæ·»åŠ æ–°çš„åŒä¹‰è¯

#### 2.1.2 æŸ¥è¯¢ä¼˜åŒ–æµç¨‹

```python
def optimize(self, query: str) -> OptimizedQuery:
    """
    ä¼˜åŒ–æŸ¥è¯¢
    
    æ­¥éª¤ï¼š
    1. æ¸…ç†æŸ¥è¯¢ï¼ˆå»é™¤å¤šä½™ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ï¼‰
    2. è¯†åˆ«æŸ¥è¯¢æ„å›¾
    3. æŸ¥è¯¢é‡å†™ï¼ˆç”Ÿæˆå¤šä¸ªå˜ä½“ï¼‰
    4. æœ¯è¯­æ‰©å±•ï¼ˆæ·»åŠ åŒä¹‰è¯ï¼‰
    """
    # 1. æ¸…ç†æŸ¥è¯¢
    cleaned_query = self._clean_query(query)
    
    # 2. è¯†åˆ«æŸ¥è¯¢æ„å›¾
    intent = self._detect_intent(cleaned_query)
    
    # 3. æŸ¥è¯¢é‡å†™
    rewritten_queries = self._rewrite_query(cleaned_query, intent)
    
    # 4. æœ¯è¯­æ‰©å±•
    expanded_terms = self._expand_terms(cleaned_query)
    
    return OptimizedQuery(
        original=query,
        rewritten=rewritten_queries,
        expanded_terms=expanded_terms,
        intent=intent
    )
```

#### 2.1.3 æ„å›¾è¯†åˆ«

```python
def _detect_intent(self, query: str) -> str:
    """
    æ£€æµ‹æŸ¥è¯¢æ„å›¾
    
    æ„å›¾ç±»å‹ï¼š
    - error_diagnosis: é”™è¯¯è¯Šæ–­ï¼ˆæŸ¥æ‰¾é”™è¯¯ç›¸å…³æ—¥å¿—ï¼‰
    - solution_seeking: å¯»æ±‚è§£å†³æ–¹æ¡ˆï¼ˆæŸ¥æ‰¾é—®é¢˜å’Œè§£å†³æ–¹æ³•ï¼‰
    - log_search: é€šç”¨æ—¥å¿—æœç´¢ï¼ˆé»˜è®¤ï¼‰
    """
    query_lower = query.lower()
    
    # é”™è¯¯ç›¸å…³æŸ¥è¯¢
    if any(word in query_lower for word in ['é”™è¯¯', 'error', 'å¼‚å¸¸', 'exception']):
        # å¦‚æœæ˜¯å¯»æ±‚è§£å†³æ–¹æ¡ˆ
        if any(word in query_lower for word in ['æ€ä¹ˆ', 'how', 'è§£å†³', 'solve', 'fix']):
            return 'solution_seeking'
        else:
            # é”™è¯¯è¯Šæ–­
            return 'error_diagnosis'
    
    # é»˜è®¤ä¸ºæ—¥å¿—æœç´¢
    return 'log_search'
```

#### 2.1.4 æŸ¥è¯¢é‡å†™

```python
def _rewrite_query(self, query: str, intent: str) -> List[str]:
    """æŸ¥è¯¢é‡å†™ï¼šæ ¹æ®æ„å›¾ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢å˜ä½“"""
    rewritten = [query]  # å§‹ç»ˆåŒ…å«åŸå§‹æŸ¥è¯¢
    
    # æ ¹æ®æ„å›¾æ·»åŠ ç‰¹å®šçš„é‡å†™è§„åˆ™
    if intent == 'error_diagnosis':
        rewritten.append(f"{query} é”™è¯¯ä¿¡æ¯")
        rewritten.append(f"{query} å¼‚å¸¸å †æ ˆ")
        
    elif intent == 'solution_seeking':
        rewritten.append(f"{query} è§£å†³æ–¹æ³•")
        rewritten.append(f"{query} ä¿®å¤æ–¹æ¡ˆ")
        rewritten.append(f"{query} è§£å†³æ–¹æ¡ˆ")
    
    return list(dict.fromkeys(rewritten))  # å»é‡
```

#### 2.1.5 æœ¯è¯­æ‰©å±•

```python
def _expand_terms(self, query: str) -> List[str]:
    """æœ¯è¯­æ‰©å±•ï¼šä½¿ç”¨åŒä¹‰è¯è¯å…¸æ‰©å±•æŸ¥è¯¢æœ¯è¯­"""
    expanded = set()
    
    # æå–æŸ¥è¯¢ä¸­çš„å…³é”®è¯
    keywords = self._extract_keywords(query)
    
    for keyword in keywords:
        # æŸ¥æ‰¾åŒä¹‰è¯
        for base_term, synonyms in self.synonym_dict.items():
            if keyword.lower() == base_term.lower() or keyword.lower() in [s.lower() for s in synonyms]:
                # æ·»åŠ åŒä¹‰è¯
                expanded.add(base_term)
                expanded.update(synonyms)
    
    return list(expanded)
```

#### 2.1.6 å¢å¼ºæŸ¥è¯¢

```python
def enhance_query_for_retrieval(self, query: str) -> str:
    """
    ä¸ºæ£€ç´¢å¢å¼ºæŸ¥è¯¢
    ç”Ÿæˆä¸€ä¸ªæœ€ä¼˜çš„æ£€ç´¢æŸ¥è¯¢
    """
    optimized = self.optimize(query)
    
    # ç»„åˆåŸå§‹æŸ¥è¯¢å’Œæ‰©å±•æœ¯è¯­
    enhanced_parts = [optimized.original]
    
    # æ·»åŠ æœ€ç›¸å…³çš„æ‰©å±•æœ¯è¯­ï¼ˆé™åˆ¶æ•°é‡é¿å…å™ªå£°ï¼‰
    if optimized.expanded_terms:
        enhanced_parts.extend(optimized.expanded_terms[:5])
    
    enhanced_query = ' '.join(enhanced_parts)
    
    return enhanced_query
```

**ç¤ºä¾‹**ï¼š
- åŸå§‹æŸ¥è¯¢ï¼š`"æ•°æ®åº“è¿æ¥é”™è¯¯"`
- å¢å¼ºåï¼š`"æ•°æ®åº“è¿æ¥é”™è¯¯ database db mysql connection error å¼‚å¸¸"`

### 2.2 é«˜çº§æŸ¥è¯¢ä¼˜åŒ–å™¨

```python
class AdvancedQueryOptimizer(QueryOptimizer):
    """
    é«˜çº§æŸ¥è¯¢ä¼˜åŒ–å™¨
    ä½¿ç”¨ LLM è¿›è¡Œæ›´æ™ºèƒ½çš„æŸ¥è¯¢æ”¹å†™
    """
    
    def optimize_with_llm(self, query: str) -> OptimizedQuery:
        """ä½¿ç”¨ LLM ä¼˜åŒ–æŸ¥è¯¢"""
        prompt = f"""è¯·å¸®æˆ‘ä¼˜åŒ–ä»¥ä¸‹æ—¥å¿—åˆ†ææŸ¥è¯¢ï¼Œæå–å…³é”®ä¿¡æ¯å’ŒåŒä¹‰è¯ã€‚

åŸå§‹æŸ¥è¯¢ï¼š{query}

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{{
    "intent": "æŸ¥è¯¢æ„å›¾ï¼ˆerror_diagnosis/solution_seeking/log_searchï¼‰",
    "rewritten": ["é‡å†™åçš„æŸ¥è¯¢1", "é‡å†™åçš„æŸ¥è¯¢2"],
    "expanded_terms": ["æ‰©å±•æœ¯è¯­1", "æ‰©å±•æœ¯è¯­2"]
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è¯´æ˜ã€‚"""
        
        response = self.llm.complete(prompt)
        result_dict = json.loads(response.text)
        
        return OptimizedQuery(
            original=query,
            rewritten=result_dict.get('rewritten', [query]),
            expanded_terms=result_dict.get('expanded_terms', []),
            intent=result_dict.get('intent', 'log_search')
        )
```

**ä¼˜åŠ¿**ï¼š
- âœ… **æ™ºèƒ½ç†è§£**ï¼šLLM ç†è§£æŸ¥è¯¢è¯­ä¹‰ï¼Œç”Ÿæˆæ›´å‡†ç¡®çš„å˜ä½“
- âœ… **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šè€ƒè™‘æŸ¥è¯¢ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆç›¸å…³æœ¯è¯­
- âœ… **å›é€€æœºåˆ¶**ï¼šLLM å¤±è´¥æ—¶å›é€€åˆ°åŸºç¡€ä¼˜åŒ–å™¨

---

## ä¸‰ã€é‡æ’åºå™¨ (`reranker.py`)

### 3.1 åŸºäºè§„åˆ™çš„é‡æ’åºå™¨

```python
class RuleBasedReranker(BaseReranker):
    """
    åŸºäºè§„åˆ™çš„é‡æ’åºå™¨
    ä½¿ç”¨å¤šç§å¯å‘å¼è§„åˆ™å¯¹ç»“æœè¿›è¡Œé‡æ’åº
    """
    
    def __init__(self, feature_weights: Optional[Dict[str, float]] = None):
        # é»˜è®¤ç‰¹å¾æƒé‡
        self.feature_weights = feature_weights or {
            'query_term_coverage': 0.3,      # æŸ¥è¯¢è¯è¦†ç›–ç‡
            'exact_match': 0.2,               # ç²¾ç¡®åŒ¹é…
            'keyword_density': 0.15,          # å…³é”®è¯å¯†åº¦
            'severity_score': 0.15,           # ä¸¥é‡æ€§åˆ†æ•°
            'length_penalty': 0.1,            # é•¿åº¦æƒ©ç½š
            'position_bias': 0.1              # ä½ç½®åå·®
        }
```

#### 3.1.1 ç‰¹å¾æå–

```python
def _extract_features(
    self,
    query: str,
    result: Any,
    position: int,
    total: int
) -> Dict[str, float]:
    """æå–ç‰¹å¾"""
    content = getattr(result, 'content', '')
    
    features = {}
    
    # 1. æŸ¥è¯¢è¯è¦†ç›–ç‡
    features['query_term_coverage'] = self._calculate_term_coverage(query, content)
    
    # 2. ç²¾ç¡®åŒ¹é…
    features['exact_match'] = self._calculate_exact_match(query, content)
    
    # 3. å…³é”®è¯å¯†åº¦
    features['keyword_density'] = self._calculate_keyword_density(query, content)
    
    # 4. ä¸¥é‡æ€§åˆ†æ•°
    if hasattr(result, 'metadata') and hasattr(result.metadata, 'severity_score'):
        features['severity_score'] = result.metadata.severity_score
    
    # 5. é•¿åº¦æƒ©ç½šï¼ˆé¿å…è¿‡é•¿æˆ–è¿‡çŸ­çš„ç»“æœï¼‰
    features['length_penalty'] = self._calculate_length_penalty(content)
    
    # 6. ä½ç½®åå·®ï¼ˆè½»å¾®æƒ©ç½šé åçš„ç»“æœï¼‰
    features['position_bias'] = 1.0 - (position / total) * 0.2
    
    return features
```

#### 3.1.2 åˆ†æ•°è®¡ç®—

```python
def rerank(
    self,
    query: str,
    results: List[Any],
    top_k: Optional[int] = None
) -> List[Any]:
    """é‡æ’åºç»“æœ"""
    # è®¡ç®—æ¯ä¸ªç»“æœçš„ç‰¹å¾åˆ†æ•°
    scored_results = []
    for idx, result in enumerate(results):
        features = self._extract_features(query, result, idx, len(results))
        rerank_score = self._calculate_score(features)
        
        # ç»„åˆåŸå§‹åˆ†æ•°å’Œé‡æ’åºåˆ†æ•°
        original_score = getattr(result, 'score', 0.5)
        final_score = 0.6 * original_score + 0.4 * rerank_score
        
        scored_results.append({
            'result': result,
            'final_score': final_score
        })
    
    # æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº
    scored_results.sort(key=lambda x: x['final_score'], reverse=True)
    
    if top_k:
        scored_results = scored_results[:top_k]
    
    return [item['result'] for item in scored_results]
```

### 3.2 å¤šæ ·æ€§é‡æ’åºå™¨

```python
class DiversityReranker(BaseReranker):
    """
    å¤šæ ·æ€§é‡æ’åºå™¨
    åœ¨ä¿è¯ç›¸å…³æ€§çš„åŒæ—¶å¢åŠ ç»“æœå¤šæ ·æ€§
    é¿å…è¿”å›è¿‡å¤šç›¸ä¼¼çš„ç»“æœ
    """
    
    def rerank(
        self,
        query: str,
        results: List[Any],
        top_k: Optional[int] = None
    ) -> List[Any]:
        """å¤šæ ·æ€§é‡æ’åºï¼ˆMMR ç®—æ³•ï¼‰"""
        # é¦–å…ˆä½¿ç”¨åŸºç¡€é‡æ’åºå™¨
        results = self.base_reranker.rerank(query, results, top_k=None)
        
        # å®ç° MMR (Maximal Marginal Relevance) ç®—æ³•
        selected = []
        remaining = results.copy()
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªï¼ˆæœ€ç›¸å…³çš„ï¼‰
        if remaining:
            selected.append(remaining.pop(0))
        
        # è¿­ä»£é€‰æ‹©åç»­ç»“æœ
        target_count = top_k if top_k else len(results)
        while remaining and len(selected) < target_count:
            best_score = -float('inf')
            best_idx = 0
            
            for idx, candidate in enumerate(remaining):
                # ç›¸å…³æ€§åˆ†æ•°
                relevance = candidate.score
                
                # ä¸å·²é€‰ç»“æœçš„æœ€å¤§ç›¸ä¼¼åº¦
                max_similarity = max(
                    self._calculate_similarity(candidate, selected_result)
                    for selected_result in selected
                )
                
                # MMR åˆ†æ•°
                mmr_score = (
                    (1 - self.diversity_weight) * relevance -
                    self.diversity_weight * max_similarity
                )
                
                if mmr_score > best_score:
                    best_score = mmr_score
                    best_idx = idx
            
            selected.append(remaining.pop(best_idx))
        
        return selected
```

**MMR ç®—æ³•**ï¼š
- **ç›®æ ‡**ï¼šåœ¨ä¿è¯ç›¸å…³æ€§çš„åŒæ—¶å¢åŠ å¤šæ ·æ€§
- **å…¬å¼**ï¼š`MMR = (1-Î») * Relevance - Î» * MaxSimilarity`
- **æ•ˆæœ**ï¼šé¿å…è¿”å›è¿‡å¤šç›¸ä¼¼çš„ç»“æœï¼Œæä¾›æ›´å…¨é¢çš„ä¿¡æ¯

---

## å››ã€RAG ç³»ç»Ÿé›†æˆ (`topklogsystem.py`)

### 4.1 é«˜çº§ RAG åˆå§‹åŒ–

```python
def _init_advanced_rag(self):
    """åˆå§‹åŒ–é«˜çº§ RAG ç»„ä»¶"""
    # 1. åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
    if self.retrieval_mode in ["hybrid", "bm25"]:
        self.hybrid_retriever = AdvancedLogRetriever(
            vector_index=self.log_index,
            documents=self.documents_list,
            alpha=0.6,  # 60% å‘é‡æƒé‡ï¼Œ40% BM25 æƒé‡
            enable_context_expansion=True
        )
    
    # 2. åˆå§‹åŒ–æŸ¥è¯¢ä¼˜åŒ–å™¨
    if self.enable_query_optimization:
        self.query_optimizer = AdvancedQueryOptimizer(llm=self.llm)
    
    # 3. åˆå§‹åŒ–é‡æ’åºå™¨
    if self.enable_reranking:
        self.reranker = create_reranker(
            reranker_type="diversity",  # ä½¿ç”¨å¤šæ ·æ€§é‡æ’åº
            diversity_weight=0.3
        )
```

### 4.2 é«˜çº§æ£€ç´¢æµç¨‹

```python
def _advanced_retrieve(
    self,
    query: str,
    top_k: int,
    filters: Optional[Dict[str, Any]] = None
) -> List[Dict]:
    """é«˜çº§æ£€ç´¢ï¼ˆæ··åˆæ£€ç´¢ + æŸ¥è¯¢ä¼˜åŒ– + é‡æ’åºï¼‰"""
    
    # 1. æŸ¥è¯¢ä¼˜åŒ–
    optimized_query = query
    if self.query_optimizer and self.enable_query_optimization:
        opt_result = self.query_optimizer.optimize(query)
        optimized_query = self.query_optimizer.enhance_query_for_retrieval(query)
        
        # å»ºè®®è¿‡æ»¤å™¨
        if not filters:
            filters = self.query_optimizer.suggest_filters(query)
    
    # 2. æ··åˆæ£€ç´¢
    candidate_count = min(top_k * self.rerank_candidate_multiplier, self.max_rerank_candidates)
    results = self.hybrid_retriever.retrieve(
        query=optimized_query,
        top_k=candidate_count,
        filters=filters,
        boost_severity=True
    )
    
    # 3. é‡æ’åº
    if self.reranker and self.enable_reranking and len(results) > 1:
        results = self.reranker.rerank(
            query=query,  # ä½¿ç”¨åŸå§‹æŸ¥è¯¢è¿›è¡Œé‡æ’åº
            results=results,
            top_k=top_k
        )
    else:
        results = results[:top_k]
    
    # 4. æ ¼å¼åŒ–ç»“æœ
    formatted_results = []
    for i, result in enumerate(results):
        formatted_results.append({
            "content": result.content,
            "score": result.score,
            "metadata": {
                "service": result.metadata.service,
                "level": result.metadata.level,
                "error_type": result.metadata.error_type,
                "component": result.metadata.component,
                "severity_score": result.metadata.severity_score
            },
            "rank": i + 1
        })
    
    return formatted_results
```

**å®Œæ•´æµç¨‹**ï¼š

```
ç”¨æˆ·æŸ¥è¯¢
    â†“
æŸ¥è¯¢ä¼˜åŒ–ï¼ˆé‡å†™ã€æ‰©å±•ã€æ„å›¾è¯†åˆ«ï¼‰
    â†“
æ··åˆæ£€ç´¢ï¼ˆBM25 + å‘é‡ï¼Œå€™é€‰æ•°é‡ = top_k Ã— 3ï¼‰
    â†“
ç»“æœåˆå¹¶ï¼ˆåŠ æƒå¹³å‡ï¼‰
    â†“
å…ƒæ•°æ®è¿‡æ»¤ï¼ˆçº§åˆ«ã€æœåŠ¡ã€ç»„ä»¶ï¼‰
    â†“
ä¸¥é‡æ€§æƒé‡æå‡
    â†“
é‡æ’åºï¼ˆè§„åˆ™ + å¤šæ ·æ€§ï¼Œè¿”å› top_kï¼‰
    â†“
æ ¼å¼åŒ–ç»“æœ
    â†“
è¿”å›ç»™ LLM
```

### 4.3 å‘é‡ç´¢å¼•æ„å»º

```python
def _build_vectorstore(self):
    """æ„å»ºå‘é‡å­˜å‚¨"""
    vector_store_path = "./data/vector_stores"
    chroma_client = chromadb.PersistentClient(path=vector_store_path)
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨é›†åˆ
    log_collection = chroma_client.get_or_create_collection("log_collection")
    log_vector_store = ChromaVectorStore(chroma_collection=log_collection)
    log_storage_context = StorageContext.from_defaults(vector_store=log_vector_store)
    
    # æ£€æŸ¥é›†åˆæ˜¯å¦ä¸ºç©º
    is_empty = len(log_collection.get(limit=1)["ids"]) == 0
    
    # åªæœ‰å½“é›†åˆä¸å­˜åœ¨æˆ–ä¸ºç©ºæ—¶æ‰é‡å»ºç´¢å¼•
    if not collection_exists or is_empty:
        if log_documents := self._load_documents(self.log_path):
            self.log_index = VectorStoreIndex.from_documents(
                log_documents,
                storage_context=log_storage_context,
                show_progress=True,
            )
    else:
        # ç›´æ¥ä½¿ç”¨ç°æœ‰ç´¢å¼•
        self.log_index = VectorStoreIndex.from_vector_store(log_vector_store)
```

**ç‰¹ç‚¹**ï¼š
- âœ… **æŒä¹…åŒ–å­˜å‚¨**ï¼šä½¿ç”¨ ChromaDB æŒä¹…åŒ–å‘é‡ç´¢å¼•
- âœ… **å¢é‡æ›´æ–°**ï¼šæ”¯æŒå¢é‡æ·»åŠ æ–‡æ¡£
- âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šå·²å­˜åœ¨ç´¢å¼•æ—¶ç›´æ¥åŠ è½½ï¼Œæ— éœ€é‡å»º

---

## äº”ã€æœåŠ¡è°ƒç”¨å±‚ (`services.py`)

### 5.1 RAG è°ƒç”¨æµç¨‹

```python
def deepseek_r1_api_call(prompt: str, query_type: str = "analysis") -> str:
    """
    è°ƒç”¨ DeepSeek API
    
    Args:
        prompt: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
        query_type: æŸ¥è¯¢ç±»å‹ï¼ˆanalysis: æ—¥å¿—åˆ†æ, general_chat: æ—¥å¸¸èŠå¤©ï¼‰
    """
    # æ ¹æ® query_type å†³å®šæ˜¯å¦ä½¿ç”¨ RAG
    if query_type == "analysis":
        # æ—¥å¿—åˆ†ææ¨¡å¼ï¼šä½¿ç”¨ RAG
        system = get_log_system()  # è·å– RAG ç³»ç»Ÿå®ä¾‹
        
        # è°ƒç”¨ RAG ç³»ç»Ÿ
        result = system.query(prompt, query_type=query_type)
        # system.query() å†…éƒ¨ä¼šï¼š
        # 1. è°ƒç”¨ retrieve_logs() è¿›è¡Œæ£€ç´¢
        # 2. è°ƒç”¨ generate_response() ç”Ÿæˆå›å¤
        
        return result["response"]
    else:
        # æ—¥å¸¸èŠå¤©æ¨¡å¼ï¼šç›´æ¥è°ƒç”¨ APIï¼Œä¸ä½¿ç”¨ RAG
        llm = DeepSeekLLM(model=CURRENT_CONFIG['llm'], timeout=60)
        messages = [ChatMessage(role="user", content=prompt)]
        response = llm.chat(messages)
        return response.message.content
```

### 5.2 RAG ç³»ç»ŸæŸ¥è¯¢

```python
def query(self, query: str, query_type: str = "analysis") -> Dict:
    """
    æ‰§è¡ŒæŸ¥è¯¢å¹¶ç”Ÿæˆå“åº”
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        query_type: æŸ¥è¯¢ç±»å‹
    """
    if query_type == "general_chat":
        # é€šç”¨å¯¹è¯æ¨¡å¼ï¼Œä¸è¿›è¡ŒRAGæ£€ç´¢
        response = self.llm.complete(prompt)
        return {"response": response.text, "retrieval_stats": 0}
    else:
        # æ—¥å¿—åˆ†ææ¨¡å¼ï¼Œè¿›è¡ŒRAGæ£€ç´¢
        # 1. æ£€ç´¢ç›¸å…³æ—¥å¿—
        log_results = self.retrieve_logs(user_query)
        
        # 2. ç”Ÿæˆå›å¤
        response = self.generate_response(user_query, log_results, query_type)
        
        return {
            "response": response,
            "retrieval_stats": len(log_results),
            "query_type": query_type
        }
```

---

## å…­ã€å®Œæ•´å®ç°æµç¨‹

### 6.1 å‰ç«¯åˆ°åç«¯çš„å®Œæ•´æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç”¨æˆ·è¾“å…¥æŸ¥è¯¢     â”‚
â”‚ "æ•°æ®åº“è¿æ¥é”™è¯¯" â”‚
â”‚ query_type:     â”‚
â”‚ "analysis"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‰ç«¯å‘é€è¯·æ±‚     â”‚
â”‚ POST /chat       â”‚
â”‚ query_type:     â”‚
â”‚ "analysis"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API è·¯ç”±å±‚       â”‚
â”‚ è¯†åˆ« query_type â”‚
â”‚ = "analysis"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æœåŠ¡å±‚           â”‚
â”‚ deepseek_r1_    â”‚
â”‚ api_call()      â”‚
â”‚ è°ƒç”¨ RAG ç³»ç»Ÿ   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG ç³»ç»Ÿ         â”‚
â”‚ 1. æŸ¥è¯¢ä¼˜åŒ–      â”‚
â”‚ 2. æ··åˆæ£€ç´¢      â”‚
â”‚ 3. é‡æ’åº        â”‚
â”‚ 4. ç”Ÿæˆå›å¤      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è¿”å›åˆ†æç»“æœ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 RAG æ£€ç´¢è¯¦ç»†æµç¨‹

```
ç”¨æˆ·æŸ¥è¯¢ï¼š"æ•°æ®åº“è¿æ¥é”™è¯¯"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤ 1: æŸ¥è¯¢ä¼˜åŒ–                 â”‚
â”‚ - æ¸…ç†æŸ¥è¯¢                      â”‚
â”‚ - è¯†åˆ«æ„å›¾ï¼šerror_diagnosis     â”‚
â”‚ - é‡å†™æŸ¥è¯¢ï¼š                    â”‚
â”‚   "æ•°æ®åº“è¿æ¥é”™è¯¯"              â”‚
â”‚   "æ•°æ®åº“è¿æ¥é”™è¯¯ é”™è¯¯ä¿¡æ¯"     â”‚
â”‚   "æ•°æ®åº“è¿æ¥é”™è¯¯ å¼‚å¸¸å †æ ˆ"     â”‚
â”‚ - æ‰©å±•æœ¯è¯­ï¼š                    â”‚
â”‚   database, db, mysql,          â”‚
â”‚   connection, error, å¼‚å¸¸       â”‚
â”‚ - å¢å¼ºæŸ¥è¯¢ï¼š                    â”‚
â”‚   "æ•°æ®åº“è¿æ¥é”™è¯¯ database db   â”‚
â”‚    mysql connection error å¼‚å¸¸" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤ 2: æ··åˆæ£€ç´¢                 â”‚
â”‚ - å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰        â”‚
â”‚   è¿”å› 30 æ¡å€™é€‰ç»“æœ            â”‚
â”‚ - BM25 æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰       â”‚
â”‚   è¿”å› 30 æ¡å€™é€‰ç»“æœ            â”‚
â”‚ - åˆå¹¶ç»“æœï¼ˆåŠ æƒå¹³å‡ï¼‰          â”‚
â”‚   å»é‡å 45 æ¡ç»“æœ              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤ 3: å…ƒæ•°æ®è¿‡æ»¤               â”‚
â”‚ - è¿‡æ»¤æ¡ä»¶ï¼šlevel="ERROR"       â”‚
â”‚ - è¿‡æ»¤åï¼š30 æ¡ç»“æœ             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤ 4: ä¸¥é‡æ€§æƒé‡æå‡           â”‚
â”‚ - ERROR çº§åˆ«æå‡ 40%            â”‚
â”‚ - é‡æ–°æ’åº                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤ 5: é‡æ’åº                   â”‚
â”‚ - è§„åˆ™é‡æ’åºï¼ˆç‰¹å¾æå–ï¼‰         â”‚
â”‚ - å¤šæ ·æ€§é‡æ’åºï¼ˆMMR ç®—æ³•ï¼‰       â”‚
â”‚ - è¿”å› top_10 ç»“æœ              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤ 6: æ„å»º Prompt              â”‚
â”‚ - æ•´åˆæ£€ç´¢ç»“æœ                  â”‚
â”‚ - åº”ç”¨ Prompt æ¨¡æ¿              â”‚
â”‚ - ç”Ÿæˆæœ€ç»ˆ Prompt               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ­¥éª¤ 7: LLM ç”Ÿæˆ                 â”‚
â”‚ - è°ƒç”¨å¤§æ¨¡å‹                    â”‚
â”‚ - ç”Ÿæˆåˆ†æç»“æœ                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ è¿”å›åˆ†æç»“æœ                     â”‚
â”‚ - é—®é¢˜æ‘˜è¦                      â”‚
â”‚ - æ ¹å› åˆ†æ                      â”‚
â”‚ - è§£å†³æ–¹æ¡ˆ                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ä¸ƒã€æ ¸å¿ƒç‰¹æ€§æ€»ç»“

### 7.1 æ··åˆæ£€ç´¢ä¼˜åŠ¿

| æ£€ç´¢æ–¹æ³• | ä¼˜åŠ¿ | é€‚ç”¨åœºæ™¯ |
|---------|------|---------|
| **å‘é‡æ£€ç´¢** | è¯­ä¹‰ç†è§£ã€åŒä¹‰è¯åŒ¹é… | è¯­ä¹‰æŸ¥è¯¢ã€æ„å›¾ç†è§£ |
| **BM25 æ£€ç´¢** | ç²¾ç¡®åŒ¹é…ã€æœ¯è¯­æŸ¥è¯¢ | å…³é”®è¯æŸ¥è¯¢ã€ç²¾ç¡®æœ¯è¯­ |
| **æ··åˆæ£€ç´¢** | ç»“åˆä¸¤è€…ä¼˜åŠ¿ | é€šç”¨åœºæ™¯ï¼Œå¹³è¡¡å‡†ç¡®ç‡å’Œå¬å›ç‡ |

### 7.2 æŸ¥è¯¢ä¼˜åŒ–ä¼˜åŠ¿

- âœ… **æå‡å¬å›ç‡**ï¼šé€šè¿‡æŸ¥è¯¢é‡å†™å’Œæœ¯è¯­æ‰©å±•ï¼Œæ‰¾åˆ°æ›´å¤šç›¸å…³ç»“æœ
- âœ… **æ„å›¾ç†è§£**ï¼šè¯†åˆ«æŸ¥è¯¢æ„å›¾ï¼Œç”Ÿæˆé’ˆå¯¹æ€§æŸ¥è¯¢å˜ä½“
- âœ… **åŒä¹‰è¯æ”¯æŒ**ï¼šè‡ªåŠ¨æ‰©å±•åŒä¹‰è¯ï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆæŸ¥è¯¢

### 7.3 é‡æ’åºä¼˜åŠ¿

- âœ… **æå‡å‡†ç¡®ç‡**ï¼šåŸºäºå¤šç‰¹å¾é‡æ’åºï¼Œæœ€ç›¸å…³ç»“æœæ’åœ¨å‰é¢
- âœ… **ç»“æœå¤šæ ·æ€§**ï¼šMMR ç®—æ³•é¿å…è¿”å›è¿‡å¤šç›¸ä¼¼ç»“æœ
- âœ… **å¯é…ç½®**ï¼šæ”¯æŒå¤šç§é‡æ’åºç­–ç•¥ï¼Œå¯æ ¹æ®åœºæ™¯é€‰æ‹©

### 7.4 ä¸“ä¸šçŸ¥è¯†è¡¥å……

- âœ… **å…ƒæ•°æ®æå–**ï¼šè‡ªåŠ¨è§£ææ—¥å¿—å…ƒæ•°æ®ï¼ˆæœåŠ¡ã€çº§åˆ«ã€ç»„ä»¶ç­‰ï¼‰
- âœ… **ä¸¥é‡æ€§è¯„åˆ†**ï¼šæ ¹æ®æ—¥å¿—çº§åˆ«è®¡ç®—ä¸¥é‡ç¨‹åº¦
- âœ… **ä¸Šä¸‹æ–‡æ‰©å±•**ï¼šæ”¯æŒä¸Šä¸‹æ–‡çª—å£ï¼Œè¿”å›ç›¸å…³æ—¥å¿—

---

## ğŸ“Š æ€»ç»“

### æ ¸å¿ƒå®ç°è¦ç‚¹

1. **æ··åˆæ£€ç´¢**ï¼š
   - BM25 + å‘é‡æ£€ç´¢
   - åŠ æƒå¹³å‡åˆå¹¶ç»“æœ
   - æ”¯æŒå…ƒæ•°æ®è¿‡æ»¤å’Œæƒé‡æå‡

2. **æŸ¥è¯¢ä¼˜åŒ–**ï¼š
   - æŸ¥è¯¢é‡å†™å’Œæœ¯è¯­æ‰©å±•
   - æ„å›¾è¯†åˆ«
   - LLM å¢å¼ºä¼˜åŒ–

3. **æ™ºèƒ½é‡æ’åº**ï¼š
   - åŸºäºè§„åˆ™çš„ç‰¹å¾æå–
   - å¤šæ ·æ€§é‡æ’åºï¼ˆMMRï¼‰
   - å¯é…ç½®çš„é‡æ’åºç­–ç•¥

4. **ç³»ç»Ÿé›†æˆ**ï¼š
   - æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•
   - å®¹é”™æœºåˆ¶ï¼Œè‡ªåŠ¨å›é€€
   - æ€§èƒ½ä¼˜åŒ–ï¼Œæ”¯æŒå¢é‡æ›´æ–°

### è®¾è®¡ä¼˜åŠ¿

- âœ… **ç²¾å‡†æ€§**ï¼šæ··åˆæ£€ç´¢ + é‡æ’åºï¼Œæ˜¾è‘—æå‡å‡†ç¡®ç‡
- âœ… **å¬å›ç‡**ï¼šæŸ¥è¯¢ä¼˜åŒ– + æœ¯è¯­æ‰©å±•ï¼Œæå‡å¬å›ç‡
- âœ… **å¯æ‰©å±•æ€§**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ·»åŠ æ–°åŠŸèƒ½
- âœ… **ä¸“ä¸šæ€§**ï¼šé’ˆå¯¹æ—¥å¿—åˆ†æé¢†åŸŸä¼˜åŒ–ï¼Œæ”¯æŒä¸“ä¸šçŸ¥è¯†

---

**æ ¸å¿ƒæ–‡ä»¶ä½ç½®**ï¼š
- æ··åˆæ£€ç´¢å™¨ï¼š`django_backend/hybrid_retriever.py`
- æŸ¥è¯¢ä¼˜åŒ–å™¨ï¼š`django_backend/query_optimizer.py`
- é‡æ’åºå™¨ï¼š`django_backend/reranker.py`
- RAG ç³»ç»Ÿï¼š`django_backend/topklogsystem.py`
- æœåŠ¡è°ƒç”¨ï¼š`django_backend/deepseek_api/services.py` (ç¬¬ 140-183 è¡Œ)

